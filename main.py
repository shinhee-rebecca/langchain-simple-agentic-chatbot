"""
ğŸ«§ ë²„ë¸”ì´ ì±—ë´‡ - ë©”ì¸ ì‹¤í–‰ íŒŒì¼
"""
from llm.model import get_llm
from prompts.persona import get_system_prompt
from tools import ALL_TOOLS
from agent.executor import create_agent


def chat():
    """ëŒ€í™” ë£¨í”„ ì‹¤í–‰"""
    # ì´ˆê¸°í™”
    llm = get_llm(temperature=0.7)
    system_prompt = get_system_prompt()
    agent = create_agent(llm, ALL_TOOLS, system_prompt, verbose=False)

    messages = []

    print("=" * 50)
    print("ğŸ«§ ë²„ë¸”ì´ ì±—ë´‡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")
    print("   (ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit')")
    print("=" * 50)

    while True:
        user_input = input("\nğŸ‘¤ You: ").strip()

        if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
            print("\nğŸ«§ ë²„ë¸”ì´: ì•ˆë…•~ ë‹¤ìŒì— ë˜ ë´! ğŸ‘‹")
            break

        if not user_input:
            continue

        messages.append({"role": "user", "content": user_input})

        response = agent.invoke({"messages": messages})

        ai_message = response["messages"][-1]
        output = ai_message.content

        print(f"\nğŸ«§ ë²„ë¸”ì´: {output}")

        messages.append({"role": "assistant", "content": output})


if __name__ == "__main__":
    chat()